{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "\n",
    "### CONNECTION STRING ###\n",
    "# remove details prior to upload. Add details before use\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "                          'Server=<ServerName>;Database=<DatabaseName>;'\n",
    "                          'Trusted_Connection=<ConnectionType>;')\n",
    "###\n",
    "\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a Clinical Trial Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clinical_trial:\n",
    "    def __init__(self,studynum,visits,cohort,specimen_types,exceptions):\n",
    "        self.studynum = studynum\n",
    "        self.visits = visits\n",
    "        self.cohort = cohort\n",
    "        self.specimen_types = specimen_types\n",
    "        self.exceptions = exceptions\n",
    "\n",
    "\n",
    "    \n",
    "reboot = clinical_trial(\"ITN080AI\", #studynum\n",
    "                    {'A':['0A', '1A', '2A', '3A', '4A', '7A', '10A', '13A', '17A', '18A', '19A', '20A', '21A', '22A', '23A', '24A', '25A','DVA'],\n",
    "                    \"B\":['0B', '1B', '3B', '5B', '7B', '9B', '10B', '11B', '12B', '13B', '14B', '15B', '16B', '17B','DVB'],\n",
    "                    }, # Visit dictionary\n",
    "                    [\"A\",\"B\"], # cohort\n",
    "                    {\"Serum Clot\":[\"H\"+\"%02d\" % i for i in list(range(1,24))],\n",
    "                  \"PBMC\":['10A','10B','10C','10D','10E','10F','10G','10H','10I'],\n",
    "                  \"Whole Blood\\nTranscriptomics\":['9A','9B'],\n",
    "                  \"Whole Blood\\nEpigenetic\":['51','52','53','54'],\n",
    "                \"Urine Supernatant\":[\"D\"+\"%02d\" % i for i in list(range(1,11))],\n",
    "                \"Urine Pellet\":['R01','R02']\n",
    "                  }, # spectype dict\n",
    "                    {\"A\":[('PBMC','1A'),('PBMC','2A'),('PBMC','3A'),\n",
    "                          ('Urine Pellet','1A'),('Urine Pellet','2A'),('Urine Pellet','3A'),\n",
    "                          ('Urine Supernatant','1A'),('Urine Supernatant','2A'),('Urine Supernatant','3A'),\n",
    "                          ('Whole Blood\\nEpigenetic','1A'),('Whole Blood\\nEpigenetic','2A'),('Whole Blood\\nEpigenetic','3A'),\n",
    "                          ('Whole Blood\\nTranscriptomics','1A'),('Whole Blood\\nTranscriptomics','2A'),('Whole Blood\\nTranscriptomics','3A')]},# exceptions\n",
    "\n",
    "                    ) \n",
    "\n",
    "reveal = clinical_trial(\"ITN086AI\", # Studynum\n",
    "                    ['0','3','6','8','9','10','WD'], # visits\n",
    "                    None, # cohort?\n",
    "                    {\"Skin Biopsy\":[\"M01\",\"M02\"],\n",
    "                    \"Whole Blood RNA\":['9A','9B','9C'],\n",
    "                    \"Whole Blood DNA\":['51','52','53','54','55','56'],\n",
    "                    \"PBMC\":[\"10A\",\"10B\",\"10C\",\"10D\",\"10E\",\"10F\"],\n",
    "                    \"Serum\":['H01', 'H02', 'H03', 'H04', 'H05', 'H06', 'H07', 'H08', 'H09', 'H10']}, # spec type dict\n",
    "                     [('Skin Biopsy','3'),('Skin Biopsy','9')] # exceptions\n",
    "                    )\n",
    "\n",
    "graduate = clinical_trial(\"ITN084AD\", # Studynum\n",
    "                    ['-2','-1','0',\"S1\",\"S3\",\"S4\",'S5', 'S6','S8', 'S9','S10', 'S11',\"S13\",'S14','S15'], # visits\n",
    "                    None, # cohorts?\n",
    "                    {'Nasal Brushing':0,'Nasal Fluid':0,'PBMC-Li Hep':0, 'Plasma-Li Hep':0, 'Serum-Clot':0,  'Whole Blood':0}, # GRADUATE specimen types granular enough. values not needed\n",
    "\n",
    "                    [(\"PBMC-Li Hep\",\"-1\"),(\"Plasma-Li Hep\",\"-1\"),\n",
    "                            (\"Nasal Brushing\",\"S1\"),(\"PBMC-Li Hep\",\"S1\"),(\"Plasma-Li Hep\",\"S1\"),(\"Whole Blood\",\"S1\"),\n",
    "                            (\"PBMC-Li Hep\",\"S4\"),(\"Plasma-Li Hep\",\"S4\"),\n",
    "                            (\"Nasal Brushing\",\"S6\"),(\"PBMC-Li Hep\",\"S6\"),(\"Plasma-Li Hep\",\"S6\"),(\"Whole Blood\",\"S6\"),\n",
    "                            (\"PBMC-Li Hep\",\"S9\"),(\"Plasma-Li Hep\",\"S9\"),\n",
    "                            (\"Nasal Brushing\",\"S11\"),(\"PBMC-Li Hep\",\"S11\"),(\"Plasma-Li Hep\",\"S11\"),(\"Whole Blood\",\"S11\"),\n",
    "                            (\"PBMC-Li Hep\",\"S14\"),(\"Plasma-Li Hep\",\"S14\"),\n",
    "                            ] # exceptions\n",
    "                    )\n",
    "\n",
    "clinical_trials = [reboot,reveal,graduate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from LabVantage. Connect to the SQL Server.\n",
    "# If there are cohorts get data for the specified cohort\n",
    "# Then, keep relevant columns and drop samples that are lost/damaged/missing.\n",
    "# Run data cleaning functions specific to the study.\n",
    "# \n",
    "def get_lv_data(ct,studynum, cohort):\n",
    "    \n",
    "    lv_query = None\n",
    "    if cohort == None:\n",
    "        lv_query = '''SELECT * FROM rpt.LabVantageVisits WHERE studynum = '{}' '''.format(studynum)\n",
    "    else:\n",
    "        lv_query = '''SELECT * FROM rpt.LabVantageVisits WHERE studynum = '{}' AND Cohort = '{}' '''.format(studynum,cohort)\n",
    "    output_df = pd.read_sql(lv_query,cnxn)\n",
    "\n",
    "    output_df = output_df[['studynum',  'Participant', 'KitBarcode',\n",
    "                            'CollectionDate',  'specimentype',\n",
    "                            'visitnum', 'barcode', 'Sample Comment', 'Cohort', 'storagestatus',\n",
    "                            'storagedisposalstatus', 'Shipping Status']]\n",
    "    output_df = output_df[~output_df[\"storagedisposalstatus\"].isin(['lostOrDamaged', 'Missing'])]\n",
    "    if ct.studynum == \"ITN080AI\":\n",
    "        output_df.drop(output_df[(output_df[\"barcode\"] == \"340236\")].index, inplace = True)\n",
    "    \n",
    "    # Rename and specify sample types only for non-graduate\n",
    "    if ct.studynum != \"ITN084AD\":\n",
    "        def specify_sample_type(bcde):\n",
    "            # Turn the barcode into a list where the first entry is the kit and the second entry is the suffix\n",
    "            bcde_components = bcde.split(\"-\")\n",
    "            # Get the suffix\n",
    "            suffix = bcde_components[1]\n",
    "            \n",
    "            specimen_type_keys = list(ct.specimen_types.keys())\n",
    "            #print(suffix)\n",
    "            for s_t in specimen_type_keys:\n",
    "                if suffix in ct.specimen_types[s_t]:\n",
    "                    return s_t\n",
    "            return None\n",
    "\n",
    "        output_df[\"specimentype\"] = output_df.apply(lambda x:specify_sample_type(x[\"barcode\"]),axis = 1)\n",
    "\n",
    "    # custom data cleaning for graduate:\n",
    "    if ct.studynum == \"ITN084AD\":\n",
    "        def assign_visit(kit,vis):\n",
    "            if vis == None:\n",
    "                if kit == \"447410\":\n",
    "                    return \"S3\"\n",
    "                elif kit == \"715208\":\n",
    "                    return \"0\"\n",
    "                elif kit == \"822140\":\n",
    "                    return \"-2\"\n",
    "                else:\n",
    "                    return vis\n",
    "            else:\n",
    "                return vis\n",
    "            \n",
    "        def assign_pid(kit,pid):\n",
    "            if pid == None:\n",
    "                if kit == \"447410\":\n",
    "                    return \"11651\"\n",
    "                elif kit == \"715208\":\n",
    "                    return \"11539\"\n",
    "                elif kit == \"822140\":\n",
    "                    return \"11302\"\n",
    "                else:\n",
    "                    return pid\n",
    "            else:\n",
    "                return pid\n",
    "            \n",
    "        output_df[\"visitnum\"] = output_df.apply(lambda x: assign_visit(x[\"KitBarcode\"],x[\"visitnum\"]),axis = 1)\n",
    "        output_df[\"Participant\"] = output_df.apply(lambda x: assign_pid(x[\"KitBarcode\"],x[\"Participant\"]),axis = 1)        \n",
    "\n",
    "    return output_df\n",
    "\n",
    "# Get Rho data\n",
    "def get_rho_data(ct,studynum,cohort):\n",
    "\n",
    "\n",
    "    # If there is/n't multiple cohorts for the study\n",
    "    if ct.cohort != None:\n",
    "        rho_query = '''SELECT DISTINCT a.[ADINFC STUDYID],a.[RHO Screening Identifier],a.[Cohort],a.[Participant ID],c.VisitKey, c.[Visit Number],c.[Visit Ordinal],c.[DaysPostScreening]\n",
    "                    FROM   [rpt].[Participant] a\n",
    "                    JOIN   [rpt].[ParticipantActivity] b\n",
    "                        ON     a.[ParticipantKey] = b.[ParticipantKey]\n",
    "                        AND    b.[Activity] IN ('Visit','UnscheduledVisit')\n",
    "                    JOIN   [rpt].[Visit] c\n",
    "                        ON     b.[VisitKey] = c.[VisitKey]\n",
    "                    JOIN   [rpt].[Site] d\n",
    "                        ON     a.[SiteKey] = d.[SiteKey]\n",
    "                    WHERE  a.[ADINFC STUDYID] = '{}' AND Cohort = 'Part {}' '''.format(studynum,cohort)\n",
    "    else:\n",
    "        rho_query = '''SELECT DISTINCT a.[ADINFC STUDYID],a.[RHO Screening Identifier],a.[Cohort],a.[Participant ID], c.VisitKey, c.[Visit Number],c.[Visit Ordinal],c.[DaysPostScreening]\n",
    "                    FROM   [rpt].[Participant] a\n",
    "                    JOIN   [rpt].[ParticipantActivity] b\n",
    "                        ON     a.[ParticipantKey] = b.[ParticipantKey]\n",
    "                        AND    b.[Activity] IN ('Visit','UnscheduledVisit')\n",
    "                    JOIN   [rpt].[Visit] c\n",
    "                        ON     b.[VisitKey] = c.[VisitKey]\n",
    "                    JOIN   [rpt].[Site] d\n",
    "                        ON     a.[SiteKey] = d.[SiteKey]\n",
    "                    WHERE  a.[ADINFC STUDYID] = '{}'  '''.format(studynum)\n",
    "    # Turn query results into a dataframe\n",
    "    output_df = pd.read_sql(rho_query,cnxn)\n",
    "    \n",
    "\n",
    "\n",
    "    # Fix the lack of pids\n",
    "    def fix_no_pid_rho(rho_si,pid):\n",
    "        if pid == None:\n",
    "            rho_si_components = rho_si.split(\"-\")\n",
    "            return rho_si_components[2]\n",
    "        else:\n",
    "            return pid\n",
    "    output_df[\"Participant ID\"] = output_df.apply(lambda x: fix_no_pid_rho(x[\"RHO Screening Identifier\"],x[\"Participant ID\"]),axis = 1)\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def get_visit_info(ct):\n",
    "\n",
    "    visit_query = '''SELECT a.[Study Number],b.[Visit Number],b.[Visit Ordinal],b.[DaysPostScreening] FROM rpt.Study a\n",
    "                    JOIN rpt.Visit b\n",
    "                        ON a.[StudyKey] = b.[Studykey]\n",
    "                        WHERE a.[Study Number] = '{}'\n",
    "                        ORDER BY [Visit Ordinal]\n",
    "                    '''.format(ct.studynum)\n",
    "    output_df = pd.read_sql(visit_query,cnxn)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "# Create a result dataframe\n",
    "def create_result_df(ct,choose_cohort,rho_records,lv_data,visit_info):\n",
    "    # Create the resulting dataframe\n",
    "    result = pd.DataFrame(columns = [\"Study\",\"Cohort\",\"Visit Number\",\"Visit Ordinal\",\"DaysPostScreening\",\"Sample Type\",\"Number at least 1 collected\",\"Number of recorded visits\",\"Percent\"])\n",
    "    \n",
    "    visit_ord_dict = dict(zip(list(visit_info[\"Visit Number\"]),list(visit_info[\"Visit Ordinal\"])))\n",
    "    days_post_dict = dict(zip(list(visit_info[\"Visit Number\"]),list(visit_info[\"DaysPostScreening\"])))\n",
    "    \n",
    "    if type(ct.cohort) == list:\n",
    "        for visit in ct.visits[choose_cohort]:\n",
    "            for sampletype in ct.specimen_types:\n",
    "                result.loc[len(result)] = [ct.studynum,choose_cohort,visit,visit_ord_dict[visit],days_post_dict[visit],sampletype,None,None,None]\n",
    "    else:\n",
    "        for visit in ct.visits:\n",
    "            for sampletype in ct.specimen_types:\n",
    "                result.loc[len(result)] = [ct.studynum,None,visit,visit_ord_dict[visit],days_post_dict[visit],sampletype,None,None,None]\n",
    "        \n",
    "\n",
    "    number_of_recorded_visits = []\n",
    "    def find_collection_stats(std,visnum,spectype):\n",
    "        # Find the number of PIDs with a visit recorded\n",
    "        rho_visits = rho_records[rho_records[\"Visit Number\"] == visnum]\n",
    "        pids_with_recorded_visit_rho = len(list(rho_visits[\"Participant ID\"].unique()))\n",
    "        pids_with_recorded_visit_lv = len(list(lv_data[lv_data[\"visitnum\"] == visnum][\"Participant\"].unique()))\n",
    "        pids_with_recorded_visit = max(pids_with_recorded_visit_rho,pids_with_recorded_visit_lv)\n",
    "        #if pids_with_recorded_visit_rho != pids_with_recorded_visit_lv:\n",
    "        #    print(ct.studynum + \" \" + visnum + \": RHO has {} visits recorded but LV has {} visits recorded\".format(str(pids_with_recorded_visit_rho),str(pids_with_recorded_visit_lv)))\n",
    "        \n",
    "        # LV data with the specimen type and visit num\n",
    "        lv_data_visit_spec = lv_data[(lv_data[\"specimentype\"] == spectype) & (lv_data[\"visitnum\"] == visnum)]\n",
    "\n",
    "        # Number of unique pids that have the spec type for that visit\n",
    "        pids_at_least_1_tube_for_this_spec_type_for_this_vis = len(list(lv_data_visit_spec[\"Participant\"].unique()))\n",
    "\n",
    "        percent = 0\n",
    "\n",
    "        if pids_with_recorded_visit == 0:\n",
    "            percent = 0\n",
    "        else:\n",
    "            percent = 100 * pids_at_least_1_tube_for_this_spec_type_for_this_vis / pids_with_recorded_visit\n",
    "        \n",
    "        number_of_recorded_visits.append(pids_with_recorded_visit)\n",
    "\n",
    "        #print(spectype + \" | \" + visnum + \": \" + str(pids_at_least_1_tube_for_this_spec_type_for_this_vis))\n",
    "\n",
    "        return pids_at_least_1_tube_for_this_spec_type_for_this_vis, pids_with_recorded_visit,round(percent)\n",
    "\n",
    "    result[[\"Number at least 1 collected\",\"Number of recorded visits\",\"Percent\"]] = result.apply(lambda x: find_collection_stats(x[\"Study\"],x[\"Visit Number\"],x[\"Sample Type\"]),axis = 1,result_type=\"expand\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create plot\n",
    "def heatmap(ct,choose_cohort,table,table_num_rec_vis):\n",
    "    # Create a new list of xlabels:\n",
    "    num_visits_per_vis = table_num_rec_vis.iloc[0,:]\n",
    "    visit_labels =[]\n",
    "\n",
    "    if type(ct.cohort) == list:\n",
    "        for ind in range(len(ct.visits[choose_cohort])):\n",
    "            visit_labels.append(\"V\"+ct.visits[choose_cohort][ind]+\"\\n\"+str(num_visits_per_vis[ind]))\n",
    "            if ind == len(ct.visits)-1 & (ct.studynum != \"ITN084AD\"):\n",
    "                visit_labels[ind] = ct.visits[choose_cohort][ind]+\"\\n\"+str(num_visits_per_vis[ind])\n",
    "    else:\n",
    "        for ind in range(len(ct.visits)):\n",
    "            visit_labels.append(\"V\"+ct.visits[ind]+\"\\n\"+str(num_visits_per_vis[ind]))\n",
    "            if ind == len(ct.visits)-1 & (ct.studynum != \"ITN084AD\"):\n",
    "                visit_labels[ind] = ct.visits[ind]+\"\\n\"+str(num_visits_per_vis[ind])\n",
    "                \n",
    "    title = ct.studynum + \": % of PIDs that have at least 1 Sample Collected for the Visit\"\n",
    "    plt.figure(figsize=(15,5))\n",
    "    cmap=sns.dark_palette(\"#69d\", reverse=True, as_cmap=True)\n",
    "    fig = sns.heatmap(table,annot= True,fmt='g',cmap=cmap,vmin = 0 ,vmax = 100)\n",
    "    fig.set_xticklabels(visit_labels, rotation=0)\n",
    "    fig.set_yticklabels(list(table.index), rotation=0)\n",
    "    fig.xaxis.tick_top()\n",
    "    fig.set(xlabel='Visit',\n",
    "        ylabel='Specimen Type',title=title)\n",
    "    \n",
    "# Get collection statistics\n",
    "def pivot_table(ct,choose_cohort,rho_records,res,lv_data):\n",
    "    number_of_recorded_visits = []\n",
    "\n",
    "    # make a pivot table to get the number of recorded visits\n",
    "    table_num_rec_vis = pd.pivot_table(res,values=\"Number of recorded visits\",index = [\"Sample Type\"],columns=[\"Visit Number\"])\n",
    "\n",
    "    # re-index the table based on the ordered list of visits\n",
    "    if type(ct.cohort) == list:\n",
    "        table_num_rec_vis = table_num_rec_vis.reindex(ct.visits[choose_cohort],axis = 1)\n",
    "    else:\n",
    "        table_num_rec_vis = table_num_rec_vis.reindex(ct.visits,axis = 1)\n",
    "\n",
    "\n",
    "    # make a pivot table for visualization\n",
    "    table = pd.pivot_table(res,values=\"Percent\",index = [\"Sample Type\"],columns=[\"Visit Number\"])\n",
    "    \n",
    "    # re-index the table based on the ordered list of visits\n",
    "    if type(ct.cohort) == list:\n",
    "        table = table.reindex(ct.visits[choose_cohort],axis = 1)\n",
    "    else:\n",
    "        table = table.reindex(ct.visits,axis = 1)\n",
    "\n",
    "\n",
    "    # Put NaNs in cells we are not expecting samples\n",
    "\n",
    "    if type(ct.cohort) == list:\n",
    "        try:\n",
    "            cohort_exceptions = ct.exceptions[choose_cohort]\n",
    "            for except_visit in cohort_exceptions:\n",
    "                table.loc[except_visit[0],except_visit[1]] = np.nan\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        for except_visit in ct.exceptions:\n",
    "            table.loc[except_visit[0],except_visit[1]] = np.nan\n",
    "    \n",
    "    return table,table_num_rec_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(lv_query,cnxn)\n",
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:101: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(rho_query,cnxn)\n",
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:124: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(visit_query,cnxn)\n",
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(lv_query,cnxn)\n",
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:101: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(rho_query,cnxn)\n",
      "C:\\Users\\lserizawa\\AppData\\Local\\Temp\\ipykernel_30416\\3730478193.py:124: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  output_df = pd.read_sql(visit_query,cnxn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Visit Number</th>\n",
       "      <th>Visit Ordinal</th>\n",
       "      <th>DaysPostScreening</th>\n",
       "      <th>Sample Type</th>\n",
       "      <th>Number at least 1 collected</th>\n",
       "      <th>Number of recorded visits</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>A</td>\n",
       "      <td>0A</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Serum Clot</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>A</td>\n",
       "      <td>0A</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>A</td>\n",
       "      <td>0A</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Whole Blood\\nTranscriptomics</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>A</td>\n",
       "      <td>0A</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Whole Blood\\nEpigenetic</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>A</td>\n",
       "      <td>0A</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urine Supernatant</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>B</td>\n",
       "      <td>DVB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>B</td>\n",
       "      <td>DVB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Whole Blood\\nTranscriptomics</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>B</td>\n",
       "      <td>DVB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Whole Blood\\nEpigenetic</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>B</td>\n",
       "      <td>DVB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urine Supernatant</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ITN080AI</td>\n",
       "      <td>B</td>\n",
       "      <td>DVB</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urine Pellet</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Study Cohort Visit Number  Visit Ordinal  DaysPostScreening  \\\n",
       "0   ITN080AI      A           0A             15                0.0   \n",
       "1   ITN080AI      A           0A             15                0.0   \n",
       "2   ITN080AI      A           0A             15                0.0   \n",
       "3   ITN080AI      A           0A             15                0.0   \n",
       "4   ITN080AI      A           0A             15                0.0   \n",
       "..       ...    ...          ...            ...                ...   \n",
       "85  ITN080AI      B          DVB            300                0.0   \n",
       "86  ITN080AI      B          DVB            300                0.0   \n",
       "87  ITN080AI      B          DVB            300                0.0   \n",
       "88  ITN080AI      B          DVB            300                0.0   \n",
       "89  ITN080AI      B          DVB            300                0.0   \n",
       "\n",
       "                     Sample Type  Number at least 1 collected  \\\n",
       "0                     Serum Clot                           17   \n",
       "1                           PBMC                           17   \n",
       "2   Whole Blood\\nTranscriptomics                           16   \n",
       "3        Whole Blood\\nEpigenetic                           17   \n",
       "4              Urine Supernatant                           17   \n",
       "..                           ...                          ...   \n",
       "85                          PBMC                            3   \n",
       "86  Whole Blood\\nTranscriptomics                            2   \n",
       "87       Whole Blood\\nEpigenetic                            3   \n",
       "88             Urine Supernatant                            3   \n",
       "89                  Urine Pellet                            3   \n",
       "\n",
       "    Number of recorded visits  Percent  \n",
       "0                          17      100  \n",
       "1                          17      100  \n",
       "2                          17       94  \n",
       "3                          17      100  \n",
       "4                          17      100  \n",
       "..                        ...      ...  \n",
       "85                          3      100  \n",
       "86                          3       67  \n",
       "87                          3      100  \n",
       "88                          3      100  \n",
       "89                          3      100  \n",
       "\n",
       "[198 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for trial in clinical_trials:\n",
    "    if type(trial.cohort) == list:\n",
    "        for chrt in trial.cohort:\n",
    "            choose_cohort = chrt\n",
    "            lv_data = get_lv_data(trial.studynum,chrt)\n",
    "            rho_data = get_rho_data(trial.studynum,chrt)\n",
    "            visit_info = get_visit_info()\n",
    "            if trial.cohort[0] == chrt:\n",
    "                result = create_result_df(rho_data,lv_data,visit_info)\n",
    "            else:\n",
    "                result = pd.concat([result,create_result_df(rho_data,lv_data,visit_info)])\n",
    "            #table,table_num_rec_vis = pivot_table(rho_data,result,lv_data)\n",
    "            #heatmap(table,table_num_rec_vis)\n",
    "    else:\n",
    "        lv_data = get_lv_data(trial.studynum,None)\n",
    "        rho_data = get_rho_data(trial.studynum,None)\n",
    "        visit_info = get_visit_info()\n",
    "        result = create_result_df(rho_data,lv_data,visit_info)\n",
    "\n",
    "        # rho_records,lv_data,visit_info,res\n",
    "        # print(lv_data)\n",
    "        # table,table_num_rec_vis = pivot_table(rho_data,result,lv_data)\n",
    "        \n",
    "        # heatmap(table,table_num_rec_vis)\n",
    "    result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
